# ETAAcademy-Adudit: 7. Static Analysis

<table>
  <tr>
    <th>title</th>
    <th>tags</th>
  </tr>
  <tr>
    <td>07 Static Analysis</td>
    <td>
      <table>
        <tr>
          <th>audit</th>
          <th>basic</th>
          <th>article</th>
          <td>Static_Analysis</td>
        </tr>
      </table>
    </td>
  </tr>
</table>

[Github](https://github.com/ETAAcademy)｜[Twitter](https://twitter.com/ETAAcademy)｜[ETA-Audit](https://github.com/ETAAcademy/ETAAcademy-Audit)

Authors: [Evta](https://twitter.com/pwhattie), looking forward to your joining

# Static Analysis Techniques to Identifying Vulnerabilities

Static analysis is a technique for analyzing code without executing it, commonly used to identify potential errors, vulnerabilities, or deviations from best practices. It covers methods like Abstract Syntax Tree (AST), Symbolic Execution, Control Flow, Data Flow, Pattern Matching, Abstract Interpretation, Cyclomatic Complexity, Taint, Dependency, and Formal Verification. For each technique, the article explains how it works, what it's used for, and the tools involved, with real-world examples.

## 1. **Abstract Syntax Tree (AST) Analysis**

- **Principle**: The source code is converted into an Abstract Syntax Tree (AST), which represents the structure of the code. Each node in the tree represents different parts of the code (such as expressions, statements, functions, etc.). By examining the structure of the AST, potential structural issues can be identified.
- **Uses**: Identifying unused variables, duplicate code blocks, uninitialized variables, potential infinite loops, and other structural problems.
- **Tools**: Slither, Mythril, and others.
- **Example**: In smart contract auditing, **Slither** uses ASTs generated by the Solidity compiler (solc) to analyze contract code. Although the AST is a simple tree structure, its nested complexity makes analysis challenging. To address this, Slither employs the **Visitor Pattern**, a design pattern that allows the definition of new operations without modifying the class structure of the objects. The Visitor Pattern recursively traverses the AST to search for specific operations or expressions.

  For example, Slither can use a custom `ExpressionVisitor` class to check for addition operations within expressions. The `HasAddition` class, which inherits from `ExpressionVisitor`, overrides the `_post_binary_operation` method to detect addition operations. Each time an addition operation is encountered, the `_result` is set to `True`, indicating that the expression contains an addition operation.

<details><summary>Code</summary>

```solidity

from slither.visitors.expression.expression import ExpressionVisitor
from slither.core.expressions.binary_operation import BinaryOperationType

class HasAddition(ExpressionVisitor):

    def result(self):
        return self._result

    def _post_binary_operation(self, expression):
        if expression.type == BinaryOperationType.ADDITION:
            self._result = True

visitor = HasAddition(expression)
print(f'The expression {expression} has an addition: {visitor.result()}')

```

</details>

---

## 2. **Symbolic Execution**

- **Principle**: Symbolic execution is an analysis technique in which the program’s inputs are treated as symbols (e.g., using `x` to represent all possible input values, rather than specific values, to ensure edge cases are not missed). During execution, symbolic data flow is tracked to explore different paths within the program. This approach helps in analyzing path-dependent issues, such as erroneous conditionals or execution paths that could lead to vulnerabilities.
- **Uses**: Symbolic execution is commonly used to detect complex control flow vulnerabilities, such as reentrancy attacks, race conditions, and others.
- **Tools**: MythX, Oyente, and others.
- **Example**: Symbolic execution can be used to reverse engineer a binary file that has been obfuscated by a virtual machine. For example, **fsvm** in openECSC 2024 is a Linux x64 binary containing a virtual machine instruction set, where the virtual machine interprets bytecode to hide the actual operations of the program. The program’s structure and the bytecode operations reveal how the virtual machine uses eight registers for various operations, such as jumps, additions, and string concatenation. By disassembling the bytecode instruction flow, it was discovered that the program’s main objective is to receive and verify the user’s flag input.

  Using symbolic execution, a custom execution environment was created to simulate each instruction of the virtual machine and track its execution paths. This method does not rely on existing symbolic execution libraries but instead manually simulates the virtual machine instruction set. By exploring all possible program paths, the pseudocode of the program was reconstructed, revealing how the flag string was validated through fixed mathematical transformations on each character. The final pseudocode showed that the program verifies the correctness of each character, outputting "ok" if all characters are correct, and "no" otherwise. This demonstrates that symbolic execution not only effectively recovers the logic of virtualized programs but also aids in solving complex CTF challenges.

<details><summary>Code</summary>

```c++

// Linux x64 binary file
void* fsbase
    int64_t rax = *(fsbase + 0x28)
    if (argc != 2)
        std::ostream::operator<<(this: std::operator<<<std::char_traits<char> >(__out: std::operator<<<std::char_traits<char> >(__out: std::operator<<<std::char_traits<char> >)))
        exit(status: 1)
        noreturn
void var_228
std: :ifstream::ifstream(this: &var_228, __s: argv[1])
void var_128
if (std::ios::fail(this: &var_128) != 0)
    std::ostream::operator<<(this: std: :operator<<<std::char_traits<char> >(__out: std: :operator<<<std::char_traits<char> >(__out: std::operator<<<std::char_traits<char> >)))
    exit(status: 1)
    noreturn
mkdir("regs", 0x1c0)
interpret(&var_228)
void* var_258 = &regs
for (void* i = &regs; i != _ITM_deregisterTMCloneTable; i = i + 0x20)
    void var_248
    std::string::string(this: &var_248)
    remove(file: std: :string::c_str(this: &var_248))
    std::string::~string(this: &var_248)
system(line: "rmdir regs")
std::ifstream::~ifstream(this: &var_228)
if (rax == *(fsbase + 0x28))
    return 0
__stack_chk_fail()
noreturn

...

// pseudocode

#include <stdio.h>

int main(int argc, char* argv[]) {
	puts("flag:");
	char flag[29];
	scanf("%s", flag);
	if ((((-flag[0]) + 111) + (((-flag[1]) + 112) + (((-flag[2]) + 101) + (((-flag[3]) + 110) + (((-flag[4]) + 69) + (((-flag[5]) + 67) + (((-flag[6]) + 83) + (((-flag[7]) + 67) + (((-flag[8]) + 123) + (((-flag[9]) + 115) + (((-flag[10]) + 117) + (((-flag[11]) + 112) + (((-flag[12]) + 101) + (((-flag[13]) + 114) + (((-flag[14]) + 101) + (((-flag[15]) + 97) + (((-flag[16]) + 115) + (((-flag[17]) + 121) + (((-flag[18]) + 118) + (((-flag[19]) + 109) + (((-flag[20]) + 99) + (((-flag[21]) + 52) + (((-flag[22]) + 101) + (((-flag[23]) + 56) + (((-flag[24]) + 55) + (((-flag[25]) + 99) + (((-flag[26]) + 52) + (((-flag[27]) + 100) + ((-flag[28]) + 125))))))))))))))))))))))))))))) != "00000000000000000000000000000") {
		puts("no");
		return 0;
	} else {
		puts("ok");
		return 0;
	}
}

```

</details>

---

## 3. **Control Flow Analysis**

- **Principle**: **Control Flow Graph (CFG)** is a graph-based representation of a program's code, primarily used to visualize the execution paths. It represents the program’s control flow through nodes and edges: nodes contain instructions or code blocks, while edges represent the flow of control (such as `if/else` statements, loops, and function calls).
- **Uses**: Control flow analysis is useful for identifying dead code, invalid branches, and uncovered code paths. By analyzing different execution paths, it helps detect potential logical errors or security vulnerabilities, such as reentrancy attacks or authorization control issues. It can also assess loop behavior and branch coverage, ensuring that all potential branches and conditions are properly tested and handled. This technique forms the basis of many static analysis methods and is often applied to detect security flaws, optimize program structure, and analyze various execution paths.
- **Tools**: Slither, Mythril, and others.
- **Example**: Static analysis tools like Slither utilize control flow graphs to help uncover potential vulnerabilities in smart contracts, such as reentrancy attacks. By visualizing the control flow graph, analysts can clearly see each execution path and its possible branches, offering a deeper understanding of the code's behavior and facilitating the identification of hidden security risks.

<details><summary>Code</summary>

```solidity

function safeAdd(uint256 a, uint256 b) internal pure returns (uint256) {
    if (a + b <= a) {
        revert();
    }
    return a + b;
}

```

</details>

<div  align="center">
<img src="https://github.com/ETAAcademy/ETAAcademy-Images/blob/main/ETAAcademy-Audit/07_CFG.png?raw=true" width="50%" />
</div>

---

## 4. **Data Flow Analysis**

- **Principle**: Data flow analysis examines how data moves throughout a program, tracking the flow of variables and function parameters, and how they are manipulated. By analyzing how different inputs affect the program's state, this technique helps identify potential security issues.
- **Uses**: It is useful for detecting uninitialized variables, potential input validation errors, and data leakage issues, among others.
- **Tools**: Slither, MythX, and others.
- **Example**: Unlike abstract syntax trees (ASTs), data flow graphs focus on how data flows during program execution rather than the program's syntactical structure. In a data flow graph, nodes represent semantic elements that carry values during program execution. For example, in the expression `x || y`, the data flow graph has corresponding nodes for the subexpressions `x` and `y`, as well as the entire expression `x || y`. An edge from `x` to `x || y` represents the fact that the value of `x` can influence the value of `x || y`, while the edge from `y` to `x || y` indicates that `y`'s value may also affect the outcome of `x || y`.

  Data flow analysis aims to infer various information about the program or its segments, especially regarding the possible values of variables. By combining control flow graphs (CFGs) with lattice operations, data flow analysis can trace the possible values of variables at different points in the program, considering the influence of control flow and eventually reaching a fixed point (or convergence). During the analysis, mathematical tools such as sets, unions, and partially ordered sets (lattices) are used to represent and compute the potential values of variables. For example, assignments, control flow branches, and loops can all affect the inferred values of variables. In practice, when the possible values of a variable are too complex or infinite, analysis tools use `⊤` (top) to indicate an excess of information that cannot be computed precisely, and `⊥` (bottom) is used to represent a variable with no possible value when it is uninitialized.

  Data flow analysis is widely applied in program optimization, error detection, and refactoring, as it effectively uncovers potential programming errors or areas for improvement. It is especially valuable when dealing with complex control flow and data dependencies, providing insights into how variables and data interact across various program execution paths.

<details><summary>Code</summary>

```python

def example(n):
    x = 0
    # x is {0}
    if n > 0:
        x = 5
        # x is {5}
    else:
        x = 42
        # x is {42}
    # x is {5, 42}
    print(x)


def example_of_infinite_sets():
    x = 0  # x is {0}
    while condition():
        x += 1  # x is {0, 1, 2, …}
    print(x)  # x is {0, 1, 2, …}


def example_of_top_with_loop():
    x = 0  # x is {0}
    while condition():
        x += 1  # x is ⊤ (could be any value)
    print(x)  # x is ⊤


def example_of_top_without_loops(n):
    x = 0  # x is {0}
    if n == 0:
        x = 1
    elif n == 1:
        x = 9
    elif n == 2:
        x = 7
    else:
        x = 3
    # x is ⊤ (top set, because it's set to one of several possible values)
    print(x)


def example_of_bottom():
    x = None  # x is ⊥ (undefined value)
    x = 42  # x is {42}
    print(x)


```

</details>

<div  align="center">
<img src="https://github.com/ETAAcademy/ETAAcademy-Images/blob/main/ETAAcademy-Audit/07_DFA.png?raw=true" width="50%" />
</div>

---

## 5. **Pattern Matching**

- **Principle**: This method involves defining known vulnerability patterns (or "signatures") and matching them against the code. Tools will scan the source code based on predefined vulnerability patterns to identify potential security issues.
- **Uses**: Pattern matching is commonly used to detect well-known vulnerability patterns such as reentrancy attacks, integer overflow, and access control flaws.
- **Tools**: Slither, MythX, and others.
- **Example**: In traditional functional programming, pattern matching is mainly used to match algebraic data types, whereas object-oriented features like inheritance and information hiding are not directly supported by this approach. However, in recent years, languages like F# and Scala have incorporated pattern matching into object-oriented programming languages, allowing developers to use more powerful matching functionalities. Pattern matching works by checking whether an expression conforms to a given pattern. One of the most common forms is **type matching**, where the dynamic type of the expression is used to select the corresponding match pattern. For example, in Scala, code can use pattern matching to handle different types of arguments, returning a value if the argument is an instance of the `Something` type or returning an empty string if it is of type `None`.

  To improve efficiency, these languages often compile pattern matching into bytecode (such as MSIL or Java bytecode), where type matching is converted into type testing (`instanceof`) and type casting (`cast`). Additionally, compilers use static analysis to optimize the code and ensure that the type matching is exhaustive, avoiding unreachable code and unsafe type casts. For instance, by using sealed classes, compilers can infer that certain type matches will always succeed, optimizing the execution path and ensuring the safety of type conversions. These optimizations not only enhance performance but also strengthen the security of the program.

<details><summary>Code</summary>

```scala

abstract sealed class Option[T]
final case class Something[T](val y : T) extends Option[T]
final case object None extends Option[Nothing]

def extract [T](x : Option[T]) : String = x match {
	case Something(y) => return y.toString();
	case None => return ””;
}

...

String extract (Option x) {
  if(x instanceOf Something)
    return ((Something) x).y. toString ();
  else if (x instanceOf None)
      return ””;
    else throw new MatchError ();
}

```

</details>

---

## 6. **Abstract Interpretation**

- **Principle**: Abstract interpretation uses abstract models to simulate the behavior of a program, capturing its potential states. This method is commonly employed to detect issues like overflows, out-of-bounds accesses, or improper memory usage.
- **Uses**: It is particularly useful in detecting and analyzing security vulnerabilities in code, such as overflow, memory access violations, and other issues in smart contracts.
- **Tools**: Mythril, Slither, SmartCheck.
- **Example**: In mathematical logic, **completeness** is an important concept that refers to whether a proof system can prove all statements that are true under its semantics. For example, Gödel's completeness theorem shows that a proof system for first-order logic can prove all statements that are true in all models. For decision procedures in logic, we expect them to be **sound** (not incorrectly declaring false propositions as true) and **complete** (able to declare all true formulas as true). In abstract interpretation, completeness is often sacrificed, especially during global analysis. For instance, interval arithmetic is used for program safety analysis, but it cannot prove all situations completely. However, it can ensure that the results are safe.

  To improve efficiency, certain solving methods may intentionally introduce incompleteness, such as using widening operators to speed up the analysis, though this can increase uncertainty. Controlling this incompleteness is crucial both theoretically and practically, ensuring that analysis results are predictable and preventing analysis failures caused by small program variations. Therefore, the balance between completeness and incompleteness must be adjusted based on the specific needs and context.

  In abstract interpretation, even if the abstract domain is sufficiently precise, it is sometimes impossible to find the necessary invariants through a particular abstract interpretation method, leading to incomplete analysis results. For example, in a data flow program, using classical interval static analysis methods and widening operators may result in a calculated interval of `[0, ∞)` but fail to prove a specific assertion. However, by using a more precise interval like `[0, 42]`, the assertion can be proven correct. This demonstrates that the issue lies not with the abstract domain (the interval) itself but with the reasoning method (the widening operation).

  Additionally, an interesting property of widening operators in relational domains is that they typically do not commute with projections. Even if some additional variables have no impact on the original variables, adding these variables may still change the analysis result. For example, in a program involving two variables `i` and `j`, interval analysis can precisely calculate the possible values of `i`, while polyhedral analysis may lose some constraints due to widening, leading to reduced precision. This incompleteness can sometimes be addressed through hierarchical analysis methods, where more subsets of variables are gradually introduced to improve accuracy.

<details><summary>Code</summary>

```c++

i = 0;
while ( true ) {
	if ( trigger ()) {
		i = i +1;
		if (i > 42) i = 0;
	}
	assert (i < 1000);
}

i =0; j =0;
while ( true ) {
	if (*) i =0; else {i =1; j =0; }
	if (i ==0) j= j +1;
}

```

</details>

---

## 7. **Complexity Analysis**

- **Principle**: This technique analyzes the complexity of code, particularly the control flow complexity and data flow complexity. By calculating metrics like Cyclomatic Complexity or other complexity indicators, it evaluates the maintainability of the code and its potential risk for errors.
- **Uses**: Identifying overly complex code blocks to reduce the difficulty of auditing. Complex code tends to have a higher likelihood of errors, so reducing complexity helps improve code quality.
- **Tools**: Slither, SonarQube.
- **Example**: **Cyclomatic Complexity**, proposed by Thomas McCabe, is an important metric for measuring program complexity. It measures the number of independent execution paths in the program, providing a quantitative assessment of code complexity. It is commonly used to evaluate the testability, maintainability, and modification risks of a program. Cyclomatic Complexity is calculated using the control flow graph, where the nodes represent basic command blocks, and the edges represent control flow paths between those blocks. The formula is:

  M = E - N + 2P

  Where:

  - E represents the number of edges (paths),
  - N represents the number of nodes (blocks),
  - P represents the number of connected components (program components or functions).

  For a simple program without control flow statements, the Cyclomatic Complexity is 1. However, the complexity increases with conditional statements (e.g., `if` statements), as each condition creates multiple execution paths.

  For example, if the source code contains a single `if` statement, the Cyclomatic Complexity would be 2, because there are two possible paths: one if the condition is true and another if the condition is false. For more complex programs with loops and multiple conditions, the Cyclomatic Complexity increases significantly.

  Cyclomatic Complexity helps not only to analyze the logical complexity of code but also aids in designing test cases to cover all possible execution paths, ensuring the correctness of the program under different scenarios. A higher Cyclomatic Complexity usually means that the code is harder to understand and maintain. Therefore, developers should aim to keep the Cyclomatic Complexity low to reduce the probability of errors and enhance code quality.

<details><summary>Code</summary>

```python

A = 10
if B > C:
    A = B
else:
    A = C

print(A)
print(B)
print(C)

```

</details>

---

## 8. **Taint Analysis**

- **Principle**: Taint Analysis is a static analysis technique used to track and analyze how untrusted data (known as "taint") propagates through a program. Tainted data typically originates from unsafe or untrusted sources, such as user inputs or external system data. If this data is not properly validated or sanitized before influencing program execution, it can lead to security vulnerabilities such as injection attacks (e.g., SQL injection, Cross-Site Scripting (XSS), etc.).

- **Uses**: Taint Analysis is primarily used to track the propagation path of untrusted data to prevent injection attacks, such as SQL injection and XSS.

- **Tools**: Slither, MythX.

- **Example**: Taint Analysis can be used to quickly identify security vulnerabilities in APIs, especially by analyzing OWASP's crAPI. By tracking the flow of untrusted data through the program, Taint Analysis helps discover potential injection attacks and other security issues. To perform Taint Analysis, the first step is to obtain the source code or binary file of the API, and, if necessary, reverse engineer the binary to restore the readable source code. The core of the analysis focuses on identifying "sources" and "sinks": sources refer to data input points that can be controlled by an attacker, while sinks are functions or operations that process this data, often representing dangerous operations.

  By tracking the flow of data between sources and sinks, attackers can identify vulnerabilities and construct attack chains to exploit these flaws. Tools like **graudit** can automate the search for dangerous sinks in the code, leading to Taint Analysis that detects command injection vulnerabilities, ultimately allowing for remote code execution (RCE) attacks. This process not only helps identify common injection attacks but also uncovers deeper security issues, demonstrating the importance of Taint Analysis in API security assessments.

  For instance, with **crAPI**, tools like **graudit** can scan Java code to find potential dangerous functions (e.g., `exec()`), and analyze how it receives data from untrusted sources. By tracing the call paths of the `exec()` function, a potential command injection vulnerability can be found. Continuing to track the data flow, the analysis shows how user input can manipulate the parameters of `exec()`, eventually identifying an API endpoint that could be exploited by attackers. This process involves multiple steps using commands like `grep`, progressively analyzing the source code to pinpoint key areas, and revealing how manipulating the `conversion_params` parameter can trigger `exec()` to execute malicious commands.

<details><summary>Code</summary>

```java
public String executeBashCommand(String command) throws lOException {
    BufferedReader b = null;
    StringBuilder output;
    logger.info("Executing BASH command:\n ", command);
    Runtime r = Runtime.getRuntime();
    // Use bash -c so we can handle things like multi commands separated by ; and
    // things like quotes, $, I, and \. My tests show that command comes as
    // one argument to bash, so we do not need to quote it to make it one thing.
    // Also, exec may object if it does not have an executable file as the first thing,
    // so having bash here makes it happy provided bash is installed and in path.
    String[] commands = {"bash", "-c", command};
    try {
        Process p = r.exec(commands);

        p.waitFor();
        b = new BufferedReader(new InputStreamReader(p.getInputStream()));

        String line ="";
        output = new StringBuilder();
        while ((line = b.readLineO) ! = null) {
            output.append(line + "\n");
        }
        return (output != null ? String.valueOf(output) : "command not found")；
    } catch (Exception e) {
        logger.error("Failed to execute bash with command: " + command);
        e.printStackTrace();
    } finally {
        b.close();
    }
    return null;
}

```

</details>

---

### 9. **Dependency Analysis**

- **Principle**: Contract Dependency Analysis examines the relationships between smart contracts and their dependencies on other contracts. It checks for malicious contracts or unsafe external dependencies that could introduce vulnerabilities.

- **Uses**: Identifying potential risks in inter-contract dependencies, such as unsafe external calls or unauthorized access.

- **Tools**: Slither, MythX.

- **Example**: State reverting is a mechanism in Solidity used for error handling and access control. During transactions, if a condition is not met, the state revert mechanism restores the smart contract's state to its original state. However, recent security incidents have shown that in the implementation of state reverts, smart contracts might include vulnerable code patterns that attackers can exploit. By manipulating transaction errors, attackers could control critical states, allowing them to profit illegally or cause Denial-of-Service (DoS) attacks.

  In one example, the **TokenGame** contract allows players to mint tokens. The `MintToken` function decides whether to increase `SheepToken` or `WolfToken` based on a random number. However, attackers can exploit the **state revert** mechanism by manipulating the `WolfToken` state, causing some states in the contract to be reverted during execution. This allows attackers to gain unfair profits.

  Existing research mainly focuses on using symbolic analysis and fuzz testing to detect vulnerabilities caused by state reverts, but these methods often only cover one subtype of State Revert Vulnerabilities (SRVs), such as illegal profit or DoS attacks. Moreover, some methods (e.g., EOSafe and WASAI) are specifically designed for WASM languages and are not applicable to Solidity smart contracts. A more universal approach to detecting SRVs in Solidity smart contracts at the bytecode level is more fitting.

  The core challenge of this approach is to build a detailed State Dependency Graph (SDG) to determine which states could be manipulated by attackers. Current research can only infer limited state dependency information and is insufficient to fully support SRV detection. Therefore, two previously overlooked types of state dependencies need to be identified: **Assertion-Related State Dependencies (ASD)** and **Temporal State Dependencies (TSD)**. ASD refers to explicit dependencies related to access control statements such as assert, revert, and require, while TSD refers to dependencies caused by transactions (i.e., function calls), a unique feature of smart contracts. By analyzing smart contract bytecode and historical transactions, these important dependencies can be inferred to construct a detailed State Dependency Graph, which can then be used to detect SRVs.

  The key is to detect potential illegal profit attacks (e.g., randomly modifying state variables to gain unfair advantage) and DoS attacks (e.g., causing denial of service) by identifying state variables' uncertainty and lack of proper access control. The detection process includes finding SRV indicators, analyzing external contract entry tracing, and performing taint propagation to identify and report state variables affected by vulnerabilities. Through these three steps, SRV vulnerabilities can be effectively identified and reported, improving the security of smart contracts.

<details><summary>Code</summary>

```solidity

contract TokenGame {
 mapping ( address = > uint256 ) public SheepToken ;
 mapping ( address = > uint256 ) public WolfToken ;
 mapping ( address = > uint256 ) public Earning ;
 ...
 function MintToken ( address account ) public {
	 uint256 seed = ( random () >> 245) % 10;
	 if ( seed != 0) {
		 SheepToken [ account ]++;}
	 else {
		 WolfToken [ account ]++;} }

 function Withdraw ( address account , unit amount ) public {
	 require ( SheepToken [ account ] >0|| WolfToken [ account ] >0) ;
	 tranferForm ( address ( this ) , account , amount ) ; }

 function PlaytoEarn ( address account , unit tokenId )
public {
	 if( isWolf ( tokenTraits [ tokenId ]) )
		 Earning [ account ]= Earning [ account ]*(2 - Rate ) ; }
 ...
}

```

</details>

---

## 10. **Formal Verification**

- **Principle**: Formal verification uses mathematical models to prove the correctness of code. By proving that the program will perform as expected under all possible inputs, it ensures that no logical flaws exist. Although formal verification requires significant computational resources, it provides the strongest guarantees.
- **Uses**: To verify the correctness of contract logic and ensure that the contract does not exhibit undefined behavior or erroneous execution.
- **Tools**: K Framework, Certora, MythX.
- **Example**: The Asterinas project uses formal verification with the Verus tool, based on SMT (Satisfiability Modulo Theories), in a four-step process. First is **Code Import**, where the necessary Rust types and functions are imported into Verus, and any unverified complex dependencies are replaced with stubs or functional specifications. Next is **Preliminary Code Proof**, during which Verus conducts an initial analysis of the code, identifying potential errors or unsafe behavior, and adds preconditions to avoid issues like overflows, such as preventing `align` from being zero. Then comes **Specification**, where developers formalize the behavior of functions using boolean expressions or abstract models to ensure compliance with specific safety and functional requirements. If Verus cannot automatically prove these properties, assertions, lemmas, or additional preconditions are introduced to assist in verification. Finally, there is **Final Code Proof**, where complex loops or recursive functions are first outlined in a proof framework with placeholders marking parts to be proven, which are gradually filled in until the entire verification process is completed. Through this series of steps, the Asterinas project ensures the security and correctness of its code, particularly in low-level memory management and `unsafe` code areas in Rust, providing strong formal verification guarantees for the system.

  In the Asterinas project, the **Cursor API** verification is performed using Verus' relational proofs. The `Cursor` struct represents an abstraction for navigating through a page table, containing the current virtual address (`va`), page table level (`level`), and a set of locks (`guards`). To ensure the correctness of the `Cursor`, an abstract model, `ConcreteCursor`, is introduced, which consists of three important parts: `tree` (the model of the entire page table), `locked_subtree` (the current locked node and its subtree), and `path` (the index path from the root to the current node). The `Cursor::relate()` method is used to link the `Cursor` and `ConcreteCursor`, verifying their relationship to ensure consistency in information like the virtual address and level.

  During the verification process, for example, to verify the `Cursor::pop_level()` function, which moves the cursor up one level, a specification is defined to describe how the `pop_level()` function should operate: it removes the last index in the path and generates a new `ConcreteCursor`. Verus is then used to prove that after calling `pop_level()`, the new `Cursor` matches the expected `ConcreteCursor` as defined in the `pop_level_spec()` specification.

  Additionally, **Refinement Invariants** are fundamental to these proofs, ensuring consistency across different levels of the page table. The `PageTableTreeModel` describes the low-level memory management page table structure, while the `PageTableFlatModel` provides the mapping from virtual addresses to physical pages. We prove how specific models (like the tree structure) refine the flat model by maintaining invariants, thereby ensuring the correctness and safety of page table traversal. These invariant proofs ensure system safety, even in the presence of `unsafe` code.

<details><summary>Code</summary>

```rust

  pub struct Cursor<'a, M: PageTableMode> {
    guards: [Option<PageTableNode>; 4],
    level: PagingLevel,
    guard_level: PagingLevel,
    va: Vaddr,
    barrier_va: Range<Vaddr>,
}

pub tracked struct ConcreteCursor {
    pub tracked tree: PageTableTreeModel,
    pub tracked locked_subtree: PageTableNodeModel,
    pub tracked path: PageTableTreePathModel,
}

pub open spec fn relate(self, model: ConcreteCursor) -> bool
       recommends
           model.inv(),
   {
   &&& self.level == NR_LEVELS() - model.path.len()
   &&& self.va == model.path.vaddr()
   &&& self.relate_locked_region(model)
 }

 pub open spec fn pop_level_spec(self) -> ConcreteCursor {
    let (tail, popped) = self.path.inner.pop_tail();
    ConcreteCursor {
        path: PageTableTreePathModel {
            inner: popped
        },
        ..self
    }
}

fn pop_level(&mut self, Tracked(model): Tracked<&ConcreteCursor>)
    requires
        old(self).inv(),
        model.inv(),
        old(self).relate(*model),
        // ...
    ensures
        self.inv(),
        self.relate(model.pop_level_spec()),
{
    // ...
}

```

</details>

---

<div  align="center">
<img src="https://github.com/ETAAcademy/ETAAcademy-Images/blob/main/ETAAcademy-Audit/07_static_analysis.gif?raw=true" width="50%" />
</div>
